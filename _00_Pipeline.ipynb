{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c650708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full._01_Data_Augmentation import augment\n",
    "\n",
    "from ipynb.fs.full._02_Train_Val_Test import create_speaker_DF\n",
    "\n",
    "from ipynb.fs.full._03_Data import create_data\n",
    "\n",
    "from ipynb.fs.full._04_Model import do_all, do_all_train, do_all_finetune, do_all_test\n",
    "\n",
    "from ipynb.fs.full._05_Eval import boxplot\n",
    "from ipynb.fs.full._05_Eval import confusionMatrix\n",
    "from ipynb.fs.full._05_Eval import time_diagramm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5cc79",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3c747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general Path of all Audios\n",
    "general_path = \"...\"\n",
    "# name of folder inside general_pah for Audios\n",
    "name = ''\n",
    "data_path = general_path + name\n",
    "# name of Augmentation ('best')\n",
    "name_aug = ''\n",
    "data_path_aug = general_path + name_aug\n",
    "# name of folder inside general_pah for testing Audios\n",
    "name_test = ''\n",
    "data_path_test = general_path + name_test\n",
    "# ndings of audio files for standard, dialect and testing\n",
    "s_ending = 'Standard'\n",
    "d_ending = 'Dialect'\n",
    "t_ending = 'FreeSpeech'\n",
    "\n",
    "# number of augmented files per original\n",
    "aug_num = 6\n",
    "# percentage for augmentation per file\n",
    "aug_perc = 1.0\n",
    "# segment length for each augmentation\n",
    "aug_len = 1.0\n",
    "\n",
    "# length of one segment\n",
    "audio_length = 5.0\n",
    "\n",
    "#model path for extracting embeddings\n",
    "model_path = \"...\\\\Models\\\\trillsson4\"\n",
    "# learning rate\n",
    "lr = 0.005\n",
    "# dropout rate\n",
    "dr = 0.5\n",
    "# units dense layer\n",
    "units = 512\n",
    "# size of one batch for trillsson Model\n",
    "batch_size_embedding = 10\n",
    "# size of one batch for CNN\n",
    "batch_size = 256\n",
    "# L1 regularization parameter used in the dense layers\n",
    "l1 = 0.04\n",
    "# L2 regularization parameter used in the dense layers\n",
    "l2 = 0.035\n",
    "#alpha for LeakyReLU\n",
    "alpha = 0.2\n",
    "# maximal number of epochs\n",
    "max_epochs = 250\n",
    "\n",
    "# number of individual runs\n",
    "runs = 25\n",
    "# pictures of first Epoch\n",
    "first_pictures = True\n",
    "# project to TB\n",
    "tb = False\n",
    "log_dir = '...'\n",
    "# Test different Hyperparameters\n",
    "hyper_test = False\n",
    "# when True the Model gets trained and weights get saved\n",
    "train_only = False\n",
    "# dialect name for training\n",
    "train_dialect = None\n",
    "# when True the Model gets finetuned on previously weights and new weights get saved\n",
    "finetune_only = False\n",
    "# speaker label for finetuning\n",
    "finetune_speaker = '' #'AM3'\n",
    "# when True the Model makes predictions on Audios in 'data_path_test'\n",
    "test_only = False\n",
    "# speaker label for testing\n",
    "test_speaker = None\n",
    "# name of calibration Method to use ('temperature_scaling', 'platt', 'isotonic', 'beta' or None)\n",
    "calibration = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a path exists\n",
    "def check_valid_path(path, path_name):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"Invalid path: {path_name} -> {path}\")\n",
    "\n",
    "# Check for test_only\n",
    "if test_only:\n",
    "    if train_only or hyper_test or tb or finetune_only:\n",
    "        raise ValueError(\"If test_only is True, then train_only, finetune_only, hyper_test and tb must be False.\")\n",
    "    if name_aug != '':\n",
    "        raise ValueError(\"If test_only is True, then name_aug must be empty.\")\n",
    "    if not test_speaker:\n",
    "        raise ValueError(\"If test_only is True, then a speaker label has to be given.\")\n",
    "    check_valid_path(data_path_test, \"data_path_test\")\n",
    "\n",
    "# Check for train_only\n",
    "if train_only:\n",
    "    if test_only or hyper_test:\n",
    "        raise ValueError(\"If train_only is True, then test_only and hyper_test must be False.\")\n",
    "    if not train_dialect:\n",
    "        raise ValueError(\"If train_only is True, then a dialect label has to be given.\")\n",
    "    check_valid_path(data_path, \"data_path\")\n",
    "    \n",
    "# Check for finetune_only\n",
    "if finetune_only:\n",
    "    if not finetune_speaker:\n",
    "        raise ValueError(\"If finetune_only is True, then a speaker label has to be given.\")\n",
    "    if train_only or hyper_test or test_only:\n",
    "        raise ValueError(\"If finetune_only is True, then train_only, hyper_test and test_only must be False.\")\n",
    "\n",
    "# Check for augmentation\n",
    "if name_aug:\n",
    "    if not (0 <= aug_perc <= 1):\n",
    "        raise ValueError(\"aug_perc must be between 0 and 1.\")\n",
    "    if not (0 <= aug_len <= audio_length):\n",
    "        raise ValueError(\"aug_len must be between 0 and audio_lengh.\")\n",
    "    if aug_num <= 0:\n",
    "        raise ValueError(\"aug_num must be greater than 0.\")\n",
    "    if aug_perc * audio_length < aug_len:\n",
    "        warnings.warn(\"aug_perc * audio_length is less than aug_len.\", UserWarning)       \n",
    "\n",
    "print(\"All checks passed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219c7887",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b005604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    augment(name_aug, data_path, data_path_aug, aug_perc, aug_num, aug_len, audio_length, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e33b9",
   "metadata": {},
   "source": [
    "## DF with all Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker = create_speaker_DF(data_path, data_path_aug, name_aug, s_ending, d_ending, t_ending)\n",
    "df_speaker = pd.read_pickle('./All_Files_.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b71736",
   "metadata": {},
   "source": [
    "## Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only and not finetune_only):\n",
    "    df_learn = create_data(model_path, audio_length, batch_size_embedding, '', False, train_dialect)\n",
    "if (name_aug != ''):\n",
    "    df_learn_aug = create_data(model_path, audio_length, batch_size_embedding, name_aug, False, train_dialect)\n",
    "    df_learn_aug = pd.read_pickle('./Data_' + name_aug + '_aug.pkl')\n",
    "if (test_only):\n",
    "    df_test = create_data(model_path, audio_length, batch_size_embedding, '', True, test_speaker)\n",
    "    df_test = pd.read_pickle('./Data_test.pkl')\n",
    "if (finetune_only):\n",
    "    df_learn = pd.read_pickle('./Data_.pkl')\n",
    "    df_finetune = df_learn[(df_learn['speaker'] == finetune_speaker) & (df_learn['class'] != 'test')]\n",
    "    df_finetune.to_pickle('./Data_finetune.pkl')\n",
    "    df_finetune.to_csv('./Data_finetune.csv',  sep=';')\n",
    "    df_finetune = pd.read_pickle('./Data_finetune.pkl')\n",
    "\n",
    "if (name_aug == ''):\n",
    "    df_learn_aug = None\n",
    "\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "    \n",
    "df_learn = pd.read_pickle('./Data_.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d17528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "929a72c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if (name_aug != ''):\n",
    "    print(df_learn_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_only:\n",
    "    print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ea59f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if finetune_only:\n",
    "    df_learn = pd.read_pickle('./Data_finetune.pkl')\n",
    "    print(df_learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445ce6b",
   "metadata": {},
   "source": [
    "### Projection of embeddings to TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a90562",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tb:\n",
    "    labels1 = np.array(df_learn['class'].tolist())\n",
    "    len_1 = len(labels1)\n",
    "    labels2 = np.array(df_learn['speaker'].tolist())\n",
    "    embeddings = np.array(df_learn['trillsson'].values.tolist())\n",
    "    if (name_aug != ''):\n",
    "            labels3 = np.array(df_learn_aug['class'].tolist())\n",
    "            labels4 = np.array(df_learn_aug['speaker'].tolist())\n",
    "            embeddings2 = np.array(df_learn_aug['trillsson'].values.tolist())\n",
    "            labels1 = np.concatenate((labels1, labels3), axis=None)\n",
    "            labels2 = np.concatenate((labels2, labels4), axis=None)\n",
    "            embeddings = np.concatenate((embeddings, embeddings2), axis=0)\n",
    "\n",
    "    with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as metadata:\n",
    "        for i in range(0, len(labels1)):\n",
    "            if i >= len_1:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i] + \"_aug\"}\\n')\n",
    "            else:\n",
    "                metadata.write(f'{labels1[i] + \"_\" + labels2[i]}\\n')\n",
    "        \n",
    "    embeddings_tensor = tf.Variable(embeddings)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(embedding=embeddings_tensor)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'metadata.tsv'\n",
    "    projector.visualize_embeddings(log_dir, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1ea9b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b36646c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only):\n",
    "    df_learned = pd.DataFrame(columns=['acc_train', 'acc_val', 'acc_test',\n",
    "                                    'loss_train', 'loss_val', 'loss_test',\n",
    "                                    'false_simplified', 'classes_x', 'classes_true', 'pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965f39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_only:\n",
    "    list_row, label_mapping = do_all_train(first_pictures, df_learn, df_learn_aug, name_aug, lr, dr, units, l1, l2, alpha, batch_size, max_epochs, calibration)\n",
    "    df_learned.loc[len(df_learned)] = list_row\n",
    "    \n",
    "elif finetune_only:\n",
    "    list_row, label_mapping = do_all_finetune(first_pictures, df_learn, df_learn_aug, name_aug, lr, dr, units, l1, l2, alpha, batch_size, max_epochs)\n",
    "    df_learned.loc[len(df_learned)] = list_row\n",
    "        \n",
    "elif test_only:\n",
    "    predictions, samples_begin, samples_end = do_all_test(df_learn, df_test, lr, dr, units, l1, l2, alpha, calibration)\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'predictions': [list(pred) for pred in predictions],\n",
    "        'samples_begin': samples_begin,\n",
    "        'samples_end': samples_end\n",
    "    })\n",
    "    predictions_df.to_csv('predictions.csv', index=False)\n",
    "    predictions_df.to_pickle('predictions.pkl')\n",
    "\n",
    "    \n",
    "else:   \n",
    "    for i in range(0, runs):\n",
    "        print('Iteration ', i, ' of ' + str(runs))\n",
    "\n",
    "        if (hyper_test):\n",
    "            lr_test = random.uniform(lr[0], lr[1])\n",
    "            dr_test = random.uniform(dr[0], dr[1])\n",
    "            l1_test = random.uniform(l1[0], l1[1])\n",
    "            l2_test = random.uniform(l2[0], l2[1])\n",
    "            alpha_test_num = random.randint(0, len(alpha)-1)\n",
    "            alpha_test = alpha[alpha_test_num]\n",
    "            units_test_num = random.randint(0, len(units)-1)\n",
    "            units_test = units[units_test_num]\n",
    "            batch_size_test_num = random.randint(0, len(batch_size)-1)\n",
    "            batch_size_test = batch_size[batch_size_test_num]\n",
    "      \n",
    "  \n",
    "        if (hyper_test):\n",
    "            list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, name_aug, i, lr_test, dr_test, units_test, l1_test, l2_test, alpha_test, batch_size_test, tb, log_dir, max_epochs)  \n",
    "        else:\n",
    "            list_row, label_mapping = do_all(first_pictures, df_learn, df_learn_aug, name_aug, i, lr, dr, units, l1, l2, alpha, batch_size, tb, log_dir, max_epochs)   \n",
    "        df_learned.loc[len(df_learned)] = list_row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d38f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not test_only): \n",
    "    with open('label_mapping.pkl', 'wb') as f:\n",
    "        pkl.dump(label_mapping, f)\n",
    "    df_learned.to_pickle('./Results_' + name + '_' + name_aug + '.pkl')\n",
    "    df_learned.to_csv('./Results_' + name + '_' + name_aug + '.csv',  sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1401cce",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_mapping.pkl', 'rb') as f:\n",
    "    label_mapping = pkl.load(f)\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c02607",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (test_only):\n",
    "    time_diagramm()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e95420a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if (not test_only and not train_only and not finetune_only):\n",
    "    boxplot('acc_test', name, name_aug)\n",
    "    confusionMatrix(name, name_aug, label_mapping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9095d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
